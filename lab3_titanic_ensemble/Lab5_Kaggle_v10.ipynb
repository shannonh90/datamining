{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 5: Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team FourFeats: Lucia, Carina, Michelle, Shannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Read the Data from a CSV file</b>  This code reads the training data into a panda data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv('Lab5_train.csv', dtype={'Age': np.float64}) #training is dataframe with training data\n",
    "test = pd.read_csv('Lab5_test.csv', dtype={'Age': np.float64}) #test is dataframe with test data\n",
    "full_data = [training, test] #full_data is dataframe with all data\n",
    "passengerid = test['PassengerID']\n",
    "passenger_list = test['PassengerID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embarked  Survived\n",
      "0        C  0.561798\n",
      "1        Q  0.366667\n",
      "2        S  0.341577\n"
     ]
    }
   ],
   "source": [
    "#2. Embarked feature has some missing values. Fill those with the most occuring value ('S)\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "print (training[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FamilySize  Survived\n",
      "0           1  0.307829\n",
      "1           2  0.555556\n",
      "2           3  0.557692\n",
      "3           4  0.758621\n",
      "4           5  0.333333\n",
      "5           6  0.190476\n",
      "6           7  0.272727\n",
      "7           8  0.000000\n",
      "8          11  0.000000\n"
     ]
    }
   ],
   "source": [
    "#3. Create a family size feature\n",
    "# https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['ParCh'] + 1\n",
    "print (training[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   IsAlone  Survived\n",
      "0        0  0.512748\n",
      "1        1  0.307829\n"
     ]
    }
   ],
   "source": [
    "#3.5 Let's also categorize people to check whether they are alone or not\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "print (training[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CategoricalFare  Survived\n",
      "0         [0, 7.896]  0.234043\n",
      "1    (7.896, 14.454]  0.290749\n",
      "2   (14.454, 31.275]  0.412281\n",
      "3  (31.275, 512.329]  0.617778\n"
     ]
    }
   ],
   "source": [
    "#4. Fare has some missing values. Replace with median. Categorize into 4 ranges. \n",
    "#https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(training['Fare'].median())\n",
    "    training['CategoricalFare'] = pd.qcut(training['Fare'], 4)\n",
    "print (training[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CategoricalAge  Survived\n",
      "0    (-0.08, 16]  0.500000\n",
      "1       (16, 32]  0.361345\n",
      "2       (32, 48]  0.355102\n",
      "3       (48, 64]  0.506849\n",
      "4       (64, 80]  0.222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# #5. Age has lots of missing values. \n",
    "# #https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n",
    "for dataset in full_data:\n",
    "    age_avg \t   = dataset['Age'].mean()\n",
    "    age_std \t   = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    \n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "training['CategoricalAge'] = pd.cut(training['Age'], 5)\n",
    "\n",
    "print (training[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # 5.1 Another way to process age\n",
    "# # http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html\n",
    "\n",
    "# def fillAges(row):\n",
    "#     if row['Sex']=='female' and row['Pclass'] == 1:\n",
    "#         if row['Title'] == 'Miss':\n",
    "#             return 30\n",
    "#         elif row['Title'] == 'Mrs':\n",
    "#             return 45\n",
    "#         elif row['Title'] == 'Officer':\n",
    "#             return 49\n",
    "#         elif row['Title'] == 'Royalty':\n",
    "#             return 39\n",
    "\n",
    "#     elif row['Sex']=='female' and row['Pclass'] == 2:\n",
    "#         if row['Title'] == 'Miss':\n",
    "#             return 20\n",
    "#         elif row['Title'] == 'Mrs':\n",
    "#             return 30\n",
    "\n",
    "#     elif row['Sex']=='female' and row['Pclass'] == 3:\n",
    "#         if row['Title'] == 'Miss':\n",
    "#             return 18\n",
    "#         elif row['Title'] == 'Mrs':\n",
    "#             return 31\n",
    "\n",
    "#     elif row['Sex']=='male' and row['Pclass'] == 1:\n",
    "#         if row['Title'] == 'Master':\n",
    "#             return 6\n",
    "#         elif row['Title'] == 'Mr':\n",
    "#             return 41.5\n",
    "#         elif row['Title'] == 'Officer':\n",
    "#             return 52\n",
    "#         elif row['Title'] == 'Royalty':\n",
    "#             return 40\n",
    "\n",
    "#     elif row['Sex']=='male' and row['Pclass'] == 2:\n",
    "#         if row['Title'] == 'Master':\n",
    "#             return 2\n",
    "#         elif row['Title'] == 'Mr':\n",
    "#             return 30\n",
    "#         elif row['Title'] == 'Officer':\n",
    "#             return 41.5\n",
    "\n",
    "#     elif row['Sex']=='male' and row['Pclass'] == 3:\n",
    "#         if row['Title'] == 'Master':\n",
    "#             return 6\n",
    "#         elif row['Title'] == 'Mr':\n",
    "#             return 26\n",
    "\n",
    "# for dataset in full_data:\n",
    "#     dataset.Age = dataset.apply(lambda r : fillAges(r) if np.isnan(r['Age']) else r['Age'], axis=1)\n",
    "\n",
    "# training['CategoricalAge'] = pd.cut(training['Age'], 5)\n",
    "\n",
    "# print (training[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex       female  male\n",
      "Title                 \n",
      "Col            0     3\n",
      "Countess       1     0\n",
      "Don            0     1\n",
      "Dr             1     4\n",
      "Jonkheer       0     1\n",
      "Lady           1     0\n",
      "Major          0     1\n",
      "Master         0    46\n",
      "Miss         185     0\n",
      "Mme            1     0\n",
      "Mr             0   530\n",
      "Mrs          133     0\n",
      "Ms             2     0\n",
      "Rev            0     5\n"
     ]
    }
   ],
   "source": [
    "#6. Let's get the title of people\n",
    "#https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n",
    "\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "    \n",
    "print(pd.crosstab(training['Title'], training['Sex']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Title  Survived\n",
      "0  Master  0.456522\n",
      "1    Miss  0.700535\n",
      "2      Mr  0.160377\n",
      "3     Mrs  0.813433\n",
      "4    Rare  0.444444\n"
     ]
    }
   ],
   "source": [
    "#6.5 We have titles, let's categorize them and check the impact on survival rate. \n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "print (training[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cabin  Survived\n",
      "0     A  0.600000\n",
      "1     B  0.784314\n",
      "2     C  0.615385\n",
      "3     D  0.696970\n",
      "4     E  0.764706\n",
      "5     F  0.769231\n",
      "6     G  0.500000\n",
      "7     T  0.000000\n",
      "8     U  0.291845\n"
     ]
    }
   ],
   "source": [
    "#7. Process cabin\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset.Cabin.fillna('U',inplace=True)\n",
    "    dataset['Cabin'] = dataset['Cabin'].map(lambda c : c[0])\n",
    "\n",
    "print (training[['Cabin', 'Survived']].groupby(['Cabin'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data Cleaning</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex  Age  Fare  Cabin  Embarked  FamilySize  IsAlone  \\\n",
      "0         0       3    1    2     0      8         1           1        1   \n",
      "1         0       2    1    2     2      8         0           2        0   \n",
      "2         0       3    1    1     0      8         0           1        1   \n",
      "3         0       2    0    3     1      4         0           1        1   \n",
      "4         0       3    0    1     0      8         0           1        1   \n",
      "5         0       3    1    1     0      8         2           1        1   \n",
      "6         0       3    1    1     2      8         0           1        1   \n",
      "7         0       3    1    2     1      8         0           3        0   \n",
      "8         1       2    0    2     2      8         0           4        0   \n",
      "9         0       3    1    1     1      8         0           1        1   \n",
      "\n",
      "   Title  Women_child  \n",
      "0      1            0  \n",
      "1      1            0  \n",
      "2      1            0  \n",
      "3      3            1  \n",
      "4      2            1  \n",
      "5      1            0  \n",
      "6      1            0  \n",
      "7      1            0  \n",
      "8      3            1  \n",
      "9      1            0  \n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n",
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n",
    "    \n",
    "    # Mapping Cabin\n",
    "    dataset.loc[ dataset['Cabin'] == 'A', 'Cabin']  \t\t\t       = 0\n",
    "    dataset.loc[ dataset['Cabin'] == 'B', 'Cabin']  \t\t\t       = 1\n",
    "    dataset.loc[ dataset['Cabin'] == 'C', 'Cabin']  \t\t\t       = 2\n",
    "    dataset.loc[ dataset['Cabin'] == 'D', 'Cabin']  \t\t\t       = 3\n",
    "    dataset.loc[ dataset['Cabin'] == 'E', 'Cabin']  \t\t\t       = 4\n",
    "    dataset.loc[ dataset['Cabin'] == 'F', 'Cabin']  \t\t\t       = 5\n",
    "    dataset.loc[ dataset['Cabin'] == 'G', 'Cabin']  \t\t\t       = 6\n",
    "    dataset.loc[ dataset['Cabin'] == 'T', 'Cabin']  \t\t\t       = 7\n",
    "    dataset.loc[ dataset['Cabin'] == 'U', 'Cabin']  \t\t\t       = 8\n",
    "    dataset['Cabin'] = dataset['Cabin'].astype(int)\n",
    "    \n",
    "    # Mapping Women and Children\n",
    "    dataset['Women_child'] = 0\n",
    "    dataset.loc[((dataset['Age'] > 0) & (dataset['Sex'] == 0)) | (dataset['Age'] == 0), 'Women_child'] = 1\n",
    "    dataset['Women_child'] = dataset['Women_child'].astype(int)\n",
    "\n",
    "# Feature Selection\n",
    "drop_elements = ['PassengerID', 'Name', 'Ticket', 'SibSp',\\\n",
    "                 'ParCh']\n",
    "training = training.drop(drop_elements, axis = 1)\n",
    "training = training.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "\n",
    "test  = test.drop(drop_elements, axis = 1)\n",
    "\n",
    "print (training.head(10))\n",
    "\n",
    "train = training.values\n",
    "test  = test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Initial Classifier Comparison</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   #probs need to pip install seaborn\n",
    "import xgboost\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, KFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "import plotly as py\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11008da58>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAFlCAYAAABbbMQ3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJiIiImKhVKiJiIiIWCgVaiIiIiIW6v8DK8jv85gGg8AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110fdb630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "\tAdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    xgboost.XGBClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    LogisticRegression()]\n",
    "\n",
    "log_cols = [\"Classifier\", \"Accuracy\"]\n",
    "log \t = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "\n",
    "X = train[0::, 1::]\n",
    "y = train[0::, 0]\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "\tX_train, X_test = X[train_index], X[test_index]\n",
    "\ty_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\t\n",
    "\tfor clf in classifiers:\n",
    "\t\tname = clf.__class__.__name__\n",
    "\t\tclf.fit(X_train, y_train)\n",
    "\t\ttrain_predictions = clf.predict(X_test)\n",
    "\t\tacc = accuracy_score(y_test, train_predictions)\n",
    "\t\tif name in acc_dict:\n",
    "\t\t\tacc_dict[name] += acc\n",
    "\t\telse:\n",
    "\t\t\tacc_dict[name] = acc\n",
    "\n",
    "\n",
    "for clf in acc_dict:\n",
    "\tacc_dict[clf] = acc_dict[clf] / 10.0\n",
    "\tlog_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n",
    "\tlog = log.append(log_entry)\n",
    "\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Classifier Accuracy')\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Output our results for the test set with SVC</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidate_classifier = SVC()\n",
    "candidate_classifier.fit(train[0::, 1::], train[0::, 0])\n",
    "result = candidate_classifier.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     11\n",
       "1    824\n",
       "2    695\n",
       "3    507\n",
       "4    685\n",
       "Name: PassengerID, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengerid[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result) #good! they're expecting 394 for each submission, have to add header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_data = {'PassengerID': passengerid, 'Survived': result}\n",
    "predicted_categories = pd.DataFrame(data = final_data)\n",
    "predicted_categories.to_csv('test_out.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidate_classifier = LogisticRegression()\n",
    "candidate_classifier.fit(train[0::, 1::], train[0::, 0])\n",
    "result = candidate_classifier.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tune Parameters</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commenting out the optimization part since it takes a long time and we have the optimal parameters already (can be found below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Optimizing Logistic Regression\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# clf = Pipeline([('LogisticRegression', LogisticRegression(max_iter=400))])\n",
    "\n",
    "# parameters = {\n",
    "#                 #'LogisticRegression__penalty': ('l1','l2'),\n",
    "#                 'LogisticRegression__C': (2 ** -3, 2 ** -2, 2 ** -1, 2 ** 0, 2 ** 1, 2 ** 2, 2 ** 3, 2 ** 4),\n",
    "#                 'LogisticRegression__solver': ('newton-cg', 'lbfgs', 'liblinear', 'sag')  #1\n",
    "#  }\n",
    "# gs_clf = GridSearchCV(clf, parameters, n_jobs=-1)\n",
    "# gs_clf = gs_clf.fit(train[0::, 1::], train[0::, 0])\n",
    "# predicted = gs_clf.predict(test)\n",
    "# # accuracy_score(dev_set.Category, predicted)\n",
    "\n",
    "# print(\"Best score: %0.3f\" % gs_clf.best_score_)\n",
    "# print(\"Best parameters set:\")\n",
    "# best_parameters = gs_clf.best_estimator_.get_params()\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Optimizing SVC\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# clf = Pipeline([('SVC', SVC(probability=True, kernel = 'rbf'))])\n",
    "\n",
    "# parameters = {\n",
    "#                 'SVC__C': (2 ** -3, 2 ** -2, 2 ** -1, 2 ** 0, 2 ** 1, 2 ** 2, 2 ** 3, 2 ** 4),  #1\n",
    "#                 'SVC__decision_function_shape': ('ovo', 'ovr', 'None'),\n",
    "#                 #'SVC__kernel': ('rbf', 'poly'), #'linear', 'poly'\n",
    "#                 'SVC__gamma': (2** -7, 2** -6, 2** -5, 2** -4, 2** -3, 2** -2, 2** -1, 2** 0, 2** 1, 2** 2, 2** 3, 2** 4, 2** 5, 2** 6, 2** 7 )\n",
    "#  }\n",
    "# gs_clf = GridSearchCV(clf, parameters, n_jobs=-1)\n",
    "# gs_clf = gs_clf.fit(train[0::, 1::], train[0::, 0])\n",
    "# predicted = gs_clf.predict(test)\n",
    "# # accuracy_score(dev_set.Category, predicted)\n",
    "\n",
    "# print(\"Best score: %0.3f\" % gs_clf.best_score_)\n",
    "# print(\"Best parameters set:\")\n",
    "# best_parameters = gs_clf.best_estimator_.get_params()\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Optimize Linear Discriminant Analysis\n",
    "\n",
    "# clf = Pipeline([('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis())])\n",
    "\n",
    "# parameters = {\n",
    "#                 'LinearDiscriminantAnalysis__solver': ('svd','lsqr','eigen')}  #1\n",
    "\n",
    "# gs_clf = GridSearchCV(clf, parameters, n_jobs=-1)\n",
    "# gs_clf = gs_clf.fit(train[0::, 1::], train[0::, 0])\n",
    "# predicted = gs_clf.predict(test)\n",
    "# # accuracy_score(dev_set.Category, predicted)\n",
    "\n",
    "# print(\"Best score: %0.3f\" % gs_clf.best_score_)\n",
    "# print(\"Best parameters set:\")\n",
    "# best_parameters = gs_clf.best_estimator_.get_params()\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Optimizing Adaboost\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# clf = Pipeline([('AdaBoostClassifier', AdaBoostClassifier())])\n",
    "# parameters = {\n",
    "#                 #'LogisticRegression__penalty': ('l1','l2'),\n",
    "#                 'AdaBoostClassifier__learning_rate': (0.25, 0.5, 0.75),\n",
    "#                 'AdaBoostClassifier__n_estimators': (50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550)\n",
    "# #                 'LogisticRegression__C': (2 ** -3, 2 ** -2, 2 ** -1, 2 ** 0, 2 ** 1, 2 ** 2, 2 ** 3, 2 ** 4),\n",
    "# #                 'LogisticRegression__solver': ('newton-cg', 'lbfgs', 'liblinear', 'sag')  #1\n",
    "#  }\n",
    "# gs_clf = GridSearchCV(clf, parameters, n_jobs=-1)\n",
    "# gs_clf = gs_clf.fit(train[0::, 1::], train[0::, 0])\n",
    "# predicted = gs_clf.predict(test)\n",
    "# # accuracy_score(dev_set.Category, predicted)\n",
    "# print(\"Best score: %0.3f\" % gs_clf.best_score_)\n",
    "# print(\"Best parameters set:\")\n",
    "# best_parameters = gs_clf.best_estimator_.get_params()\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidate_classifier = SVC(C = 1, gamma = 0.03125, kernel = 'rbf', decision_function_shape = 'ovo')\n",
    "candidate_classifier.fit(train[0::, 1::], train[0::, 0])\n",
    "result = candidate_classifier.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data = {'PassengerID': passengerid, 'Survived': result}\n",
    "predicted_categories = pd.DataFrame(data = final_data)\n",
    "\n",
    "# output without ensembling:\n",
    "# predicted_categories.to_csv('test_7.csv' , index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble method\n",
    "\n",
    "We used the same framework outlined in this website using the best models from our previous analysis:\n",
    "https://www.kaggle.com/arthurtok/titanic/introduction-to-ensembling-stacking-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/arthurtok/titanic/introduction-to-ensembling-stacking-in-python\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def mix(x):\n",
    "    n_methods = len(classifiers)\n",
    "    y_mix = [np.multiply(x[i], y_[i]) for i in range(n_methods)]\n",
    "    y_mix = np.sum(y_mix, axis=0)\n",
    "    y_mix = np.array([round(y).astype(int) for y in y_mix])\n",
    "    acc = accuracy_score(y_test, y_mix)\n",
    "    return -acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/arthurtok/titanic/introduction-to-ensembling-stacking-in-python\n",
    "\n",
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = training.shape[0]\n",
    "ntest = test.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "#kf = KFold(n_splits= NFOLDS, random_state=SEED)\n",
    "kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n",
    "\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n",
    "        \n",
    "#     def feature_imp(self,x,y):\n",
    "#         print(self.clf.fit(x,y).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/arthurtok/titanic/introduction-to-ensembling-stacking-in-python\n",
    "\n",
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "\n",
    "# Logistic parameters\n",
    "lg_params = {\n",
    "    'C': 0.5,\n",
    "    'solver': 'liblinear'\n",
    "}\n",
    "\n",
    "\n",
    "# LinearDiscriminantAnalysis parameters\n",
    "lda_params = {\n",
    "    'solver': 'svd'\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 50,\n",
    "    'learning_rate' : 0.25\n",
    "}\n",
    "\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'rbf',\n",
    "    'C' : 1, \n",
    "    'gamma' : 0.03125, \n",
    "    'decision_function_shape' : 'ovo'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create 4 objects that represent our 4 models\n",
    "lg = SklearnHelper(clf=LogisticRegression, seed=SEED, params=lg_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)\n",
    "# lda = SklearnHelper(clf=LinearDiscriminantAnalysis, seed=SEED, params=lda_params)\n",
    "#cannot get LDA to work -- not including it in the ensemble model anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\n",
    "y_train = training['Survived'].ravel()\n",
    "train = training.drop(['Survived'], axis=1)\n",
    "x_train = train.values # Creates an array of the train data\n",
    "x_test = test # Creats an array of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \n",
    "svc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier\n",
    "lg_oof_train, lg_oof_test = get_oof(lg, x_train, y_train, x_test) # Logistic Regresion \n",
    "# lda_oof_train, lda_oof_test = get_oof(lda,x_train, y_train, x_test) # Linear Discriminant Analysis\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.46922184, -1.20728759, -0.23266437,  0.20922092, -0.14708945,\n",
       "         0.11872573, -0.37117348, -0.20703255,  0.40770348,  1.18618318]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression(C=0.5, solver='liblinear')\n",
    "lg.fit(x_train,y_train).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14  0.04  0.18  0.06  0.12  0.02  0.16  0.    0.16  0.12]\n"
     ]
    }
   ],
   "source": [
    "ada_feature = ada.feature_importances(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# svc_feature = svc.feature_importances(x_train,y_train) -- too many features to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lg_feature = [-0.48764476, -1.0898199,  -0.2371944,   0.2102665,  -0.14545518,  0.11431281,\n",
    "              -0.38205732, -0.20223201,  0.39227969,  1.35330996]\n",
    "ada_feature = [0.12,  0.04,  0.18,  0.08,  0.12,  0.02,  0.18,  0, 0.14,  0.12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = train.columns.values\n",
    "# Create a dataframe with features\n",
    "feature_dataframe = pd.DataFrame( {'features': cols, 'Logistic Regression feature importances': lg_feature,\n",
    "                                   'AdaBoost feature importances': ada_feature})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": [
           -0.48764476,
           -1.0898199,
           -0.2371944,
           0.2102665,
           -0.14545518,
           0.11431281,
           -0.38205732,
           -0.20223201,
           0.39227969,
           1.35330996
          ],
          "colorscale": "Portland",
          "showscale": true,
          "size": 25,
          "sizemode": "diameter",
          "sizeref": 1
         },
         "mode": "markers",
         "text": [
          "Pclass",
          "Sex",
          "Age",
          "Fare",
          "Cabin",
          "Embarked",
          "FamilySize",
          "IsAlone",
          "Title",
          "Women_child"
         ],
         "type": "scatter",
         "x": [
          "Pclass",
          "Sex",
          "Age",
          "Fare",
          "Cabin",
          "Embarked",
          "FamilySize",
          "IsAlone",
          "Title",
          "Women_child"
         ],
         "y": [
          -0.48764476,
          -1.0898199,
          -0.2371944,
          0.2102665,
          -0.14545518,
          0.11431281,
          -0.38205732,
          -0.20223201,
          0.39227969,
          1.35330996
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "hovermode": "closest",
        "showlegend": false,
        "title": "Logistic Regression Feature Importance",
        "yaxis": {
         "gridwidth": 2,
         "ticklen": 5,
         "title": "Feature Importance"
        }
       }
      },
      "text/html": [
       "<div id=\"952d8c52-9d0f-4ee7-be3b-9e44d4050f4e\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"952d8c52-9d0f-4ee7-be3b-9e44d4050f4e\", [{\"type\": \"scatter\", \"marker\": {\"colorscale\": \"Portland\", \"size\": 25, \"color\": [-0.48764476, -1.0898199, -0.2371944, 0.2102665, -0.14545518, 0.11431281, -0.38205732, -0.20223201, 0.39227969, 1.35330996], \"sizeref\": 1, \"showscale\": true, \"sizemode\": \"diameter\"}, \"mode\": \"markers\", \"x\": [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Cabin\", \"Embarked\", \"FamilySize\", \"IsAlone\", \"Title\", \"Women_child\"], \"y\": [-0.48764476, -1.0898199, -0.2371944, 0.2102665, -0.14545518, 0.11431281, -0.38205732, -0.20223201, 0.39227969, 1.35330996], \"text\": [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Cabin\", \"Embarked\", \"FamilySize\", \"IsAlone\", \"Title\", \"Women_child\"]}], {\"hovermode\": \"closest\", \"yaxis\": {\"gridwidth\": 2, \"ticklen\": 5, \"title\": \"Feature Importance\"}, \"showlegend\": false, \"title\": \"Logistic Regression Feature Importance\", \"autosize\": true}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": [
           0.12,
           0.04,
           0.18,
           0.08,
           0.12,
           0.02,
           0.18,
           0,
           0.14,
           0.12
          ],
          "colorscale": "Portland",
          "showscale": true,
          "size": 25,
          "sizemode": "diameter",
          "sizeref": 1
         },
         "mode": "markers",
         "text": [
          "Pclass",
          "Sex",
          "Age",
          "Fare",
          "Cabin",
          "Embarked",
          "FamilySize",
          "IsAlone",
          "Title",
          "Women_child"
         ],
         "type": "scatter",
         "x": [
          "Pclass",
          "Sex",
          "Age",
          "Fare",
          "Cabin",
          "Embarked",
          "FamilySize",
          "IsAlone",
          "Title",
          "Women_child"
         ],
         "y": [
          0.12,
          0.04,
          0.18,
          0.08,
          0.12,
          0.02,
          0.18,
          0,
          0.14,
          0.12
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "hovermode": "closest",
        "showlegend": false,
        "title": "AdaBoost Feature Importance",
        "yaxis": {
         "gridwidth": 2,
         "ticklen": 5,
         "title": "Feature Importance"
        }
       }
      },
      "text/html": [
       "<div id=\"e1ff0b8f-4e39-4cc1-a6eb-005d15c88c07\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"e1ff0b8f-4e39-4cc1-a6eb-005d15c88c07\", [{\"type\": \"scatter\", \"marker\": {\"colorscale\": \"Portland\", \"size\": 25, \"color\": [0.12, 0.04, 0.18, 0.08, 0.12, 0.02, 0.18, 0.0, 0.14, 0.12], \"sizeref\": 1, \"showscale\": true, \"sizemode\": \"diameter\"}, \"mode\": \"markers\", \"x\": [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Cabin\", \"Embarked\", \"FamilySize\", \"IsAlone\", \"Title\", \"Women_child\"], \"y\": [0.12, 0.04, 0.18, 0.08, 0.12, 0.02, 0.18, 0.0, 0.14, 0.12], \"text\": [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Cabin\", \"Embarked\", \"FamilySize\", \"IsAlone\", \"Title\", \"Women_child\"]}], {\"hovermode\": \"closest\", \"yaxis\": {\"gridwidth\": 2, \"ticklen\": 5, \"title\": \"Feature Importance\"}, \"showlegend\": false, \"title\": \"AdaBoost Feature Importance\", \"autosize\": true}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "# Scatter plot Logistic\n",
    "trace = go.Scatter(\n",
    "    y = feature_dataframe['Logistic Regression feature importances'].values,\n",
    "    x = feature_dataframe['features'].values,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1,\n",
    "        size = 25,\n",
    "#       size= feature_dataframe['Logistic Regression feature importances'].values,\n",
    "        #color = np.random.randn(500), #set color equal to a variable\n",
    "        color = feature_dataframe['Logistic Regression feature importances'].values,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = feature_dataframe['features'].values\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Logistic Regression Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "#     xaxis= dict(\n",
    "#         title= 'Pop',\n",
    "#         ticklen= 5,\n",
    "#         zeroline= False,\n",
    "#         gridwidth= 2,\n",
    "#     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig,filename='scatter2010') \n",
    "\n",
    "# Scatter plot AdaBoost\n",
    "trace = go.Scatter(\n",
    "    y = feature_dataframe['AdaBoost feature importances'].values,\n",
    "    x = feature_dataframe['features'].values,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1,\n",
    "        size = 25,\n",
    "#       size= feature_dataframe['AdaBoost feature importances'].values,\n",
    "        #color = np.random.randn(500), #set color equal to a variable\n",
    "        color = feature_dataframe['AdaBoost feature importances'].values,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = feature_dataframe['features'].values\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'AdaBoost Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "#     xaxis= dict(\n",
    "#         title= 'Pop',\n",
    "#         ticklen= 5,\n",
    "#         zeroline= False,\n",
    "#         gridwidth= 2,\n",
    "#     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig,filename='scatter2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost feature importances</th>\n",
       "      <th>Logistic Regression feature importances</th>\n",
       "      <th>features</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.487645</td>\n",
       "      <td>Pclass</td>\n",
       "      <td>-0.183822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04</td>\n",
       "      <td>-1.089820</td>\n",
       "      <td>Sex</td>\n",
       "      <td>-0.524910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.237194</td>\n",
       "      <td>Age</td>\n",
       "      <td>-0.028597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AdaBoost feature importances  Logistic Regression feature importances  \\\n",
       "0                          0.12                                -0.487645   \n",
       "1                          0.04                                -1.089820   \n",
       "2                          0.18                                -0.237194   \n",
       "\n",
       "  features      mean  \n",
       "0   Pclass -0.183822  \n",
       "1      Sex -0.524910  \n",
       "2      Age -0.028597  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the new column containing the average of values\n",
    "\n",
    "feature_dataframe['mean'] = feature_dataframe.mean(axis= 1) # axis = 1 computes the mean row-wise\n",
    "feature_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": [
           -0.18382238,
           -0.52490995,
           -0.028597200000000003,
           0.14513325,
           -0.012727589999999997,
           0.067156405,
           -0.10102865999999999,
           -0.101116005,
           0.266139845,
           0.73665498
          ],
          "colorscale": "Portland",
          "reversescale": false,
          "showscale": true
         },
         "opacity": 0.6,
         "type": "bar",
         "width": 0.5,
         "x": [
          "Pclass",
          "Sex",
          "Age",
          "Fare",
          "Cabin",
          "Embarked",
          "FamilySize",
          "IsAlone",
          "Title",
          "Women_child"
         ],
         "y": [
          -0.18382238,
          -0.52490995,
          -0.028597200000000003,
          0.14513325,
          -0.012727589999999997,
          0.067156405,
          -0.10102865999999999,
          -0.101116005,
          0.266139845,
          0.73665498
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "hovermode": "closest",
        "showlegend": false,
        "title": "Barplots of Mean Feature Importance",
        "yaxis": {
         "gridwidth": 2,
         "ticklen": 5,
         "title": "Feature Importance"
        }
       }
      },
      "text/html": [
       "<div id=\"7ccfb345-4b11-4a2e-ac55-c3aa91b0b899\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7ccfb345-4b11-4a2e-ac55-c3aa91b0b899\", [{\"type\": \"bar\", \"marker\": {\"colorscale\": \"Portland\", \"showscale\": true, \"reversescale\": false, \"color\": [-0.18382238, -0.52490995, -0.028597200000000003, 0.14513325, -0.012727589999999997, 0.067156405, -0.10102865999999999, -0.101116005, 0.266139845, 0.73665498]}, \"opacity\": 0.6, \"y\": [-0.18382238, -0.52490995, -0.028597200000000003, 0.14513325, -0.012727589999999997, 0.067156405, -0.10102865999999999, -0.101116005, 0.266139845, 0.73665498], \"x\": [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Cabin\", \"Embarked\", \"FamilySize\", \"IsAlone\", \"Title\", \"Women_child\"], \"width\": 0.5}], {\"hovermode\": \"closest\", \"yaxis\": {\"gridwidth\": 2, \"ticklen\": 5, \"title\": \"Feature Importance\"}, \"showlegend\": false, \"title\": \"Barplots of Mean Feature Importance\", \"autosize\": true}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = feature_dataframe['mean'].values\n",
    "x = feature_dataframe['features'].values\n",
    "data = [go.Bar(\n",
    "            x= x,\n",
    "             y= y,\n",
    "            width = 0.5,\n",
    "            marker=dict(\n",
    "               color = feature_dataframe['mean'].values,\n",
    "            colorscale='Portland',\n",
    "            showscale=True,\n",
    "            reversescale = False\n",
    "            ),\n",
    "            opacity=0.6\n",
    "        )]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Barplots of Mean Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "#     xaxis= dict(\n",
    "#         title= 'Pop',\n",
    "#         ticklen= 5,\n",
    "#         zeroline= False,\n",
    "#         gridwidth= 2,\n",
    "#     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename='bar-direct-labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AdaBoost  LogisticRegression\n",
       "0       0.0                 0.0\n",
       "1       0.0                 0.0\n",
       "2       0.0                 0.0\n",
       "3       1.0                 1.0\n",
       "4       1.0                 1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_train = pd.DataFrame( {'LogisticRegression': lg_oof_train.ravel(), 'AdaBoost': ada_oof_train.ravel()\n",
    "    })\n",
    "base_predictions_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.concatenate(( lg_oof_train, ada_oof_train, svc_oof_train), axis=1)\n",
    "x_test = np.concatenate(( lg_oof_test, ada_oof_test, svc_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm = xgboost.XGBClassifier(\n",
    "    #learning_rate = 0.02,\n",
    " n_estimators= 2000,\n",
    " max_depth= 4,\n",
    " min_child_weight= 2,\n",
    " #gamma=1,\n",
    " gamma=0.9,                        \n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " scale_pos_weight=1).fit(x_train, y_train)\n",
    "predictions = gbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82513661202185795"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate Submission File \n",
    "StackingSubmission = pd.DataFrame({ 'PassengerID': passengerid,\n",
    "                            'Survived': predictions })\n",
    "StackingSubmission.to_csv(\"test_v10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Reference Materials</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Data manipulation (only on training so far)\n",
    "\n",
    "# # 1. Make Pclass three separate dummy variables \n",
    "# classes = pd.get_dummies(training.Pclass, prefix = 'Class')\n",
    "# classes.columns = ['First Class', 'Second Class', 'Third Class']\n",
    "# training = pd.concat([training,classes], axis = 1)\n",
    "# Passenger_class = training['Pclass']\n",
    "# del training['Pclass']\n",
    "# cols = training.columns.tolist()\n",
    "# cols = ['PassengerID','Survived','First Class','Second Class','Third Class','Name','Sex','Age','SibSp','ParCh','Ticket','Fare','Cabin','Embarked']\n",
    "# training = training[cols]\n",
    "\n",
    "# # 2. Make Sex a dummy variable \n",
    "# sex = pd.get_dummies(training['Sex'])\n",
    "# male = sex['male']\n",
    "# del sex['male']\n",
    "# training = pd.concat([training,sex], axis = 1)\n",
    "# cols = training.columns.tolist()\n",
    "# cols = ['PassengerID','Survived', 'First Class','Second Class','Third Class','Name', 'female', 'Age', 'SibSp', 'ParCh', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
    "# training = training[cols]\n",
    "\n",
    "# # 3. Make embarking ports dummy variables. First, though fill NA with most common value, S\n",
    "# for dataset in full_data:\n",
    "#     dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "# print (training[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())\n",
    "\n",
    "# port = pd.get_dummies(training['Embarked'])\n",
    "# port.columns = ['Cherbourg', 'Queenstown', 'Southampton']\n",
    "# embarked = training['Embarked']\n",
    "# del training['Embarked']\n",
    "# training = pd.concat([training,port], axis = 1)\n",
    "# training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Later Strategy</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discovered the use of Pipelines as a way to support trying out the performance of various feature selection options as well as parameters for various classifiers. Much of this strategy came from the discussion of linear and SV models from lecture as well as the Scikit-Learn website http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "We both tried various parameters for classifiers, relying on GridSearch, and below displays our code and results. Due to the computational load of doing a GridSearch (combinatorial growth), we both experimented with parameters on our separate machines in order to develop the best algorithm quicker.\n",
    "\n",
    "1. Feature Selection attempted:\n",
    "    1. Families vs siblings\n",
    "2. Classifiers used:\n",
    "    1. Linear: Naive Bayes, Linear Regression, Stochastic Gradiant Descent\n",
    "    2. SVC and Linear SVC (One vs One, One vs Many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Pipeline Template</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pipeline attempts (the uncommented are the final parameters for his best classifier) \n",
    "# #derived from http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "# text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), tokenizer=LemmaTokenizer(), max_df=0.25,token_pattern=r'\\b\\w+\\b', stop_words=\"english\")),\n",
    "#                       ('tfidf', TfidfTransformer(use_idf=True,norm='l2')),\n",
    "#                       #('clf', SVC(C=1000000.0, gamma='auto', kernel='rbf'))])\n",
    "#                       # ('clf', LinearSVC(C=1.0, random_state=69, penalty='l2', dual=True, tol=1e-5))])\n",
    "#                       #('clf', OneVsOneClassifier(LinearSVC(random_state=0)))])                    \n",
    "#                       ('clf', SGDClassifier(loss='hinge', alpha=1e-5, penalty='elasticnet', n_iter=50, random_state=69))])\n",
    "# _ = text_clf.fit(train_set[\"Review Text\"], train_set.Category)\n",
    "# predicted = text_clf.predict(dev_set[\"Review Text\"])\n",
    "# accuracy_score(dev_set.Category, predicted)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
