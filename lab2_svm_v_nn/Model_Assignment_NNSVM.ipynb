{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: SVM + Neural Networks #\n",
    "Yiyi Chen & Sayan Sanyal  \n",
    "2017.02.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>year</th>\n",
       "      <th>eyecolor</th>\n",
       "      <th>height</th>\n",
       "      <th>miles</th>\n",
       "      <th>brothers</th>\n",
       "      <th>sisters</th>\n",
       "      <th>computertime</th>\n",
       "      <th>exercise</th>\n",
       "      <th>exercisehours</th>\n",
       "      <th>musiccds</th>\n",
       "      <th>playgames</th>\n",
       "      <th>watchtv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1303</td>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>second</td>\n",
       "      <td>green</td>\n",
       "      <td>73.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>male</td>\n",
       "      <td>20</td>\n",
       "      <td>third</td>\n",
       "      <td>other</td>\n",
       "      <td>71.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>fourth</td>\n",
       "      <td>hazel</td>\n",
       "      <td>75.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1415</td>\n",
       "      <td>male</td>\n",
       "      <td>19</td>\n",
       "      <td>second</td>\n",
       "      <td>brown</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>616</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>fourth</td>\n",
       "      <td>hazel</td>\n",
       "      <td>71.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 gender  age    year eyecolor  height  miles  brothers  sisters  \\\n",
       "0        1303   male   20  second    green    73.0  210.0         0        1   \n",
       "1          36   male   20   third    other    71.0   90.0         1        0   \n",
       "2         489   male   22  fourth    hazel    75.0  200.0         0        1   \n",
       "3        1415   male   19  second    brown    72.0   35.0         2        2   \n",
       "4         616   male   22  fourth    hazel    71.0   15.0         2        1   \n",
       "\n",
       "   computertime exercise  exercisehours  musiccds  playgames  watchtv  \n",
       "0          10.0      Yes            5.0      50.0        1.0     15.0  \n",
       "1          15.0      Yes            4.0      10.0        0.0      1.0  \n",
       "2           1.0      Yes            2.0     150.0        1.0     10.0  \n",
       "3          20.0      Yes            5.0     100.0        0.0      7.0  \n",
       "4          10.0      Yes            7.0      10.0        0.0      5.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./lab_4_training.csv')\n",
    "df_test = pd.read_csv('./lab_4_test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 1###\n",
    "Calculate a baseline accuracy measure using the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "majority_gender = df_train['gender'].value_counts().idxmax()\n",
    "feature = 'gender'\n",
    "\n",
    "def get_accuracy(df, feature, majority_label):\n",
    "    accuracy = df[df[feature] == majority_label].shape[0]/df.shape[0]\n",
    "    print('accuracy: {:.3f}%'.format(accuracy*100))\n",
    "    \n",
    "def get_accuracy_clf(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('accuracy: {:.3f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 1.a**  \n",
    "Find the majority class in the training set. If you always predicted this class in the training set, what would your accuracy be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 53.774%\n"
     ]
    }
   ],
   "source": [
    "get_accuracy(df_train, feature, majority_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.b**   \n",
    "If you always predicted this same class (majority from the training set) in the test set, what would your accuracy be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 52.261%\n"
     ]
    }
   ],
   "source": [
    "get_accuracy(df_test, feature, majority_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 2 ###\n",
    "Get started with Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_train['height'].reshape(-1, 1)\n",
    "y_train = df_train['gender'].map(lambda x: 0 if x == 'female' else 1)\n",
    "X_test = df_test['height'].reshape(-1, 1)\n",
    "y_test = df_test['gender'].map(lambda x: 0 if x == 'female' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.a**   \n",
    "Choose a NN implementation and specify which you choose. Be sure the implementation allows you to modify the number of hidden layers and hidden nodes per layer.  \n",
    "\n",
    "NOTE: When possible, specify the logsig (sigmoid/logistc) function as the transfer function for the output node and use Levenberg-Marquardt backpropagation (lbfgs). It is possible to specify logsig or logistic in Sklearn MLPclassifier (Neural net).  \n",
    "\n",
    "**Answer**:  \n",
    "sklearn.neural_network.MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(10), \n",
    "                    activation='logistic', \n",
    "                    solver='lbfgs', \n",
    "                    random_state=32462781) # random_state = 324627814 finds a bad local minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.b**   \n",
    "Train a neural network with a single 10 node hidden layer. Only use the Height feature of the dataset to predict the Gender. You will have to change Gender to a 0 and 1 class. After training, use your trained model to predict the class using the height feature from the training set. What was the accuracy of this prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 84.654%\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_train, y_train)\n",
    "print('accuracy: {:.3f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.c**  \n",
    "Take the trained model from question 2.b and use it to predict the test set. This can be accomplished by taking the trained model and giving it the Height feature values from the test set. What is the accuracy of this model on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 85.427%\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy: {:.3f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.d**   \n",
    "Neural Networks tend to prefer smaller, normalized feature values. Try taking the log of the height feature in both training and testing sets or use a Standard Scalar operation in SKlearn to centre and normalize the data between 0-1 for continuous values. Repeat question 2.c with the log version and the normalized and centered version of this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log normalization\n",
      "accuracy: 85.427%\n"
     ]
    }
   ],
   "source": [
    "# log version\n",
    "X_train_log = np.log(X_train)\n",
    "X_test_log = np.log(X_test)\n",
    "\n",
    "print('log normalization')\n",
    "get_accuracy_clf(clf, X_train_log, y_train, X_test_log, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaler normalization\n",
      "accuracy: 85.427%\n"
     ]
    }
   ],
   "source": [
    "# normalized and centered version using a Standard scaler\n",
    "X_train_norm = StandardScaler().fit_transform(X_train)\n",
    "X_test_norm = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "print('Standard Scaler normalization')\n",
    "get_accuracy_clf(clf, X_train_norm, y_train, X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax Scaler normalization\n",
      "accuracy: 73.618%\n"
     ]
    }
   ],
   "source": [
    "# normalized and centered version using a MinMax scaler\n",
    "X_train_norm = MinMaxScaler().fit_transform(X_train)\n",
    "X_test_norm = MinMaxScaler().fit_transform(X_test)\n",
    "\n",
    "print('MinMax Scaler normalization')\n",
    "get_accuracy_clf(clf, X_train_norm, y_train, X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 3 ###\n",
    "Get started with Support Vector Machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.a**   \n",
    "Chosen a SVM implementation and specify which you choose. Be sure the implementation allows you to choose between linear and RBF kernels.\n",
    "\n",
    "**Answer**:   \n",
    "sklearn.svm.SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.b**   \n",
    "Use the same dataset from 2.b using the linear kernel to find training set prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 83.396%\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', random_state=286501204)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_train, y_train)\n",
    "print('accuracy: {:.3f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.c**   \n",
    "Use the same dataset from 2.b using the linear kernel to find test set prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 83.166%\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy: {:.3f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.d**   \n",
    "Use the same dataset from 2.b using the RBF kernel  to find training set prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 84.654%\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', random_state=286501204)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_train, y_train)\n",
    "print('accuracy: {:.3f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.e**   \n",
    "Use the same dataset from 2.b using the RBF kernel  to find test set prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 85.427%\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy: {:.3f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.f**   \n",
    "Use the same dataset from 2.d (log) using the RBF to find test set prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log normalization\n",
      "accuracy: 85.427%\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', random_state=286501204)\n",
    "print('log normalization')\n",
    "get_accuracy_clf(clf, X_train_log, y_train, X_test_log, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.g**   \n",
    "Z-score is a normalization technique. It is the value of a feature minus the average value for that feature in the training set, divided by the standard deviation of that feature in the training set. Repeat question 3.f using Z-score and note if there is any difference in accuracy and comment on why there is a change or no change in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaler normalization\n",
      "accuracy: 85.427%\n"
     ]
    }
   ],
   "source": [
    "# normalized and centered version using a Standard scaler\n",
    "X_train_norm = StandardScaler().fit_transform(X_train)\n",
    "X_test_norm = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "print('Standard Scaler normalization')\n",
    "get_accuracy_clf(clf, X_train_norm, y_train, X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no change in accuracy as normalisation makes a difference in distance based algorithms when there is a confluence of multiple dimensions on the distance metric. Since we are dealing with only one dimension in this exercise, normalising doesn't help remove the confluence of multiple dimensions, because there isn't any!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Question 4 ###\n",
    "The rest of features in this dataset barring a few are categorical. Neither ML method accepts categorical features, so transform year, eyecolor, exercise into a set of binary features, one feature per unique original feature value, and mark the binary feature as ‘1’ if the feature value matches the original value and ‘0’ otherwise. Using only these binary variable transformed features, train and predict the class of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean up one malformatted data entry\n",
    "# here I use get_dummies to encode categorical variables into binary features\n",
    "# later I use label encoder and one hot encoder for the same task\n",
    "df_train['year'].replace('first\"', 'first', inplace=True)\n",
    "df_test['year'].replace('first\"', 'first', inplace=True)\n",
    "X_train = pd.get_dummies(df_train[['year', 'eyecolor', 'exercise']])\n",
    "X_test = pd.get_dummies(df_test[['year', 'eyecolor', 'exercise']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.a**    \n",
    "What was your accuracy using Neural Network with a single 10 node hidden layer? During training, use a maximum number of iterations of 50. (Expected training time: ~15 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 59.548%\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(10), \n",
    "                    activation='logistic', \n",
    "                    max_iter=50,\n",
    "                    solver='lbfgs', \n",
    "                    random_state=32462781)\n",
    "\n",
    "get_accuracy_clf(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question 4.b**    \n",
    "What was your accuracy using a SVM with RBF kernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 58.794%\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', random_state=286501204)\n",
    "\n",
    "get_accuracy_clf(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 5###\n",
    "Using a NN, does height + eye color predict the test set class better by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try out different preprocessing to encode categorical variables\n",
    "# here I use label encoder and one hot encoder, previously I used get_dummies\n",
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# train data\n",
    "X_train_eyecolor = le.fit_transform(df_train['eyecolor'])\n",
    "X_train_eyecolor = ohe.fit_transform(X_train_eyecolor.reshape(-1, 1)).toarray()\n",
    "X_train_height = df_train['height'].reshape(-1,1).copy()\n",
    "\n",
    "# test data\n",
    "X_test_eyecolor = ohe.transform(le.transform(df_test['eyecolor']).reshape(-1, 1)).toarray()\n",
    "X_test_height = df_test['height'].reshape(-1,1).copy()\n",
    "\n",
    "columns = list(le.classes_) + ['height']\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(10), \n",
    "                    activation='logistic', \n",
    "                    solver='lbfgs', \n",
    "                    random_state=32462781)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.a**  \n",
    "Keeping the original feature values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 85.930%\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.DataFrame(np.hstack((X_train_eyecolor, X_train_height)), columns=columns)\n",
    "X_test = pd.DataFrame(np.hstack((X_test_eyecolor, X_test_height)), columns=columns)\n",
    "\n",
    "get_accuracy_clf(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.b**  \n",
    "Taking the log of the original values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 85.930%\n"
     ]
    }
   ],
   "source": [
    "X_train_height = np.log(df_train['height']).reshape(-1,1).copy()\n",
    "X_train = pd.DataFrame(np.hstack((X_train_eyecolor, X_train_height)), columns=columns)\n",
    "\n",
    "X_test_height = np.log(df_test['height']).reshape(-1,1).copy()\n",
    "X_test = pd.DataFrame(np.hstack((X_test_eyecolor, X_test_height)), columns=columns)\n",
    "\n",
    "get_accuracy_clf(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.c**  \n",
    "Taking the Z-score of the original values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 86.935%\n"
     ]
    }
   ],
   "source": [
    "X_train_height = StandardScaler().fit_transform(df_train['height'].reshape(-1,1)).copy()\n",
    "X_train = pd.DataFrame(np.hstack((X_train_eyecolor, X_train_height)), columns=columns)\n",
    "\n",
    "X_test_height = StandardScaler().fit_transform(df_test['height'].reshape(-1,1)).copy()\n",
    "X_test = pd.DataFrame(np.hstack((X_test_eyecolor, X_test_height)), columns=columns)\n",
    "\n",
    "get_accuracy_clf(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 6 ###\n",
    "Repeat question 5 for exercise hours + eye color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original features: \n",
      "accuracy: 56.030%\n",
      "log of exercise hours: \n",
      "accuracy: 57.789%\n",
      "z-score hours: \n",
      "accuracy: 56.784%\n"
     ]
    }
   ],
   "source": [
    "# 6.a\n",
    "X_train_exercise = df_train['exercisehours'].reshape(-1,1).copy()\n",
    "X_train = pd.DataFrame(np.hstack((X_train_eyecolor, X_train_exercise)), columns=columns)\n",
    "\n",
    "X_test_exercise = df_test['exercisehours'].reshape(-1,1).copy()\n",
    "X_test = pd.DataFrame(np.hstack((X_test_eyecolor, X_test_exercise)), columns=columns)\n",
    "\n",
    "print('original features: ')\n",
    "get_accuracy_clf(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# 6.b\n",
    "# Handle log(0) by adding 1 to all exercise hours\n",
    "X_train_exercise = np.log(df_train['exercisehours'].reshape(-1,1)+1).copy()\n",
    "X_train = pd.DataFrame(np.hstack((X_train_eyecolor, X_train_exercise)), columns=columns)\n",
    "\n",
    "X_test_exercise = np.log(df_test['exercisehours'].reshape(-1,1)+1).copy()\n",
    "X_test = pd.DataFrame(np.hstack((X_test_eyecolor, X_test_exercise)), columns=columns)\n",
    "\n",
    "print('log of exercise hours: ')\n",
    "get_accuracy_clf(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# 6.c\n",
    "X_train_exercise = StandardScaler().fit_transform(df_train['exercisehours'].reshape(-1,1)).copy()\n",
    "X_train = pd.DataFrame(np.hstack((X_train_eyecolor, X_train_exercise)), columns=columns)\n",
    "\n",
    "X_test_exercise = StandardScaler().fit_transform(df_test['exercisehours'].reshape(-1,1)).copy()\n",
    "X_test = pd.DataFrame(np.hstack((X_test_eyecolor, X_test_exercise)), columns=columns)\n",
    "\n",
    "print('z-score hours: ')\n",
    "get_accuracy_clf(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 7###\n",
    "Combine the features from question 4, 5, and exercise hours from question 6 (using the best normalization feature set form questions 5 and 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# year, eyecolor, exercise, height, exercisehours\n",
    "df_train['year'].replace('first\"', 'first', inplace=True)\n",
    "df_test['year'].replace('first\"', 'first', inplace=True)\n",
    "\n",
    "X_train_categorical = pd.get_dummies(df_train[['year', 'eyecolor', 'exercise']])\n",
    "X_test_categorical = pd.get_dummies(df_test[['year', 'eyecolor', 'exercise']])\n",
    "\n",
    "X_train_height = StandardScaler().fit_transform(df_train['height'].reshape(-1,1)).copy()\n",
    "X_test_height = StandardScaler().fit_transform(df_test['height'].reshape(-1,1)).copy()\n",
    "\n",
    "X_train_exercise = df_train['exercisehours'].reshape(-1,1).copy()\n",
    "X_test_exercise = df_test['exercisehours'].reshape(-1,1).copy()\n",
    "\n",
    "columns = list(X_train_categorical.columns) + ['height', 'exercisehours']\n",
    "\n",
    "X_train = pd.DataFrame(np.hstack((X_train_categorical, \n",
    "                                  X_train_height, \n",
    "                                  X_train_exercise)), \n",
    "                       columns=columns)\n",
    "X_test = pd.DataFrame(np.hstack((X_test_categorical, \n",
    "                                 X_test_height, \n",
    "                                 X_test_exercise)), \n",
    "                      columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.a**  \n",
    "What was the NN accuracy on the test set using the single 10 node hidden layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 86.683%\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(10), \n",
    "                    activation='logistic', \n",
    "                    solver='lbfgs', \n",
    "                    random_state=32462781)\n",
    "\n",
    "get_accuracy_clf(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.b**  \n",
    "What was the SVM accuracy on the test set the RBF kernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 86.432%\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', random_state=286501204)\n",
    "\n",
    "get_accuracy_clf(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Question 8###\n",
    "Can you improve your test set prediction accuracy by 5% or more?  \n",
    "\n",
    "See how close to that milestone of improvement you can get by modifying the tuning parameters of either Neural Networks (the number of hidden layers, number of hidden nodes in each layer, the learning rate aka mu) or with SVM (choosing kernel, C, and gamma). A great guide to tuning parameters is explained in this guide: http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf. \n",
    "\n",
    "While the guide is specific to SVM and in particular the C and gamma parameters of the RBF kernel, the method applies to generally to any ML technique with tuning parameters. This question will incorporate using different holdout strategies to conduct tuning on the training set before using the best model to predict the test set. Note that you may reduce the size of the training set and you may also use any feature set and transformation of features you like to improve the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NN with MLP Classifier\n",
    "# Search for best model on training data\n",
    "featurizer = DictVectorizer()\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "model = MLPClassifier()\n",
    "\n",
    "pipeline = Pipeline([('featurize', featurizer), ('scale', scaler), ('clf', model)])\n",
    "\n",
    "# initial parameter grid used to evaluate the accuray of \n",
    "# diffferent parameter combinations. \n",
    "# we have included the final parameter grid used below\n",
    "original_param_grid = [{\n",
    "        'clf__activation': ['logistic', 'tanh', 'relu'],\n",
    "        'clf__alpha':[0.0001, 0.001, 0.1],\n",
    "        'clf__solver':['lbfgs', 'sgd', 'adam'],\n",
    "        'clf__max_iter':[100, 200, 300, 500, 1000],\n",
    "        'clf__random_state':[1]\n",
    "    }]\n",
    "\n",
    "def get_best_score(X_train, y_train, X_val, y_val, pipeline, param_grid):\n",
    "    best_score, scores, best_grid = 0, [], None\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        pipeline.set_params(**params)\n",
    "        pipeline = pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_val)\n",
    "        score = accuracy_score(y_pred, y_val)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_grid = params\n",
    "    return best_score, best_grid\n",
    "\n",
    "def get_accuracy(pipeline, params, X_train, y_train, X_test, y_test, action_description):\n",
    "    pipeline.set_params(**params)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    score = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Score after {}: {:.4f}%\".format(action_description, score))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question 8.a**  \n",
    "What was your best accuracy on the test set using the training set as your holdout? (for this question the training set is used for training AND testing)  \n",
    "\n",
    "For example, specify some value of mu and C for the RBF SVM kernel. Use the training set to train the model then use the training set again to test the accuracy of the model. Try different values for C and mu, again training and testing on the training set. Take the most accurate model from your trials and use it to predict the real test set. Report your accuracy. Note that you should only be predicting the test set ONCE   \n",
    "\n",
    "**Answer**  \n",
    "Trying out using neural network (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = df_train[[\"exercisehours\", \"eyecolor\", \"year\", \"exercise\", \"height\"]].copy().to_dict(orient='records')\n",
    "y_train = df_train['gender']\n",
    "\n",
    "X_val = df_train[[\"exercisehours\", \"eyecolor\", \"year\", \"exercise\", \"height\"]].copy().to_dict(orient='records')\n",
    "y_val = df_train['gender']\n",
    "\n",
    "X_test = df_test[[\"exercisehours\", \"eyecolor\", \"year\", \"exercise\", \"height\"]].copy().to_dict(orient='records')\n",
    "y_test = df_test['gender']\n",
    "\n",
    "# final parameter grid for 8.a. the initial one is included above for reference\n",
    "param_grid = [{\n",
    "        'clf__activation': ['tanh'],\n",
    "        'clf__alpha':[0.001],\n",
    "        'clf__solver':['lbfgs'],\n",
    "        'clf__max_iter':[100000, 500000],\n",
    "        'clf__random_state':[1]\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92201\n",
      "Grid: {'clf__activation': 'tanh', 'clf__alpha': 0.001, 'clf__max_iter': 100000, 'clf__random_state': 1, 'clf__solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "best_score, best_grid = get_best_score(X_train, y_train, X_val, y_val, pipeline, param_grid)\n",
    "print(\"Accuracy: {:.5f}\".format(best_score))\n",
    "print(\"Grid: {}\".format(best_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score after just tuning on training: 92.2111%\n"
     ]
    }
   ],
   "source": [
    "y_pred = get_accuracy(pipeline, best_grid, X_train, y_train, X_test, y_test, \n",
    "                      'just tuning on training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.b**   \n",
    "What was your best accuracy on the test set using a 70% train 30% holdout?  \n",
    "\n",
    "For this question, split the rows of your training set into a subset containing 70% of the rows and another containing the remaining 30%. Train on the 70% and test of the 30%. Tune your parameters and then take the model with the best accuracy on the 30% and use it to predict the real test set. Report your accuracy. Again, prediction of the test set should only be done ONCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# updating X_train, y_train, X_val, y_val with 70/30 split\n",
    "X = df_train[[\"exercisehours\", \"eyecolor\", \"year\", \"exercise\", \"height\"]].copy()\n",
    "y = df_train['gender']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=424242)\n",
    "X_train = X_train.to_dict(orient='records')\n",
    "X_val = X_val.to_dict(orient='records')\n",
    "\n",
    "# final parameter grid for 8.b. the initial one is included above for reference\n",
    "param_grid = [{\n",
    "        'clf__hidden_layer_sizes': [(5,),(4,),(3,)],\n",
    "        'clf__activation': ['tanh', 'relu'],\n",
    "        'clf__alpha':[0.001, 0.1],\n",
    "        'clf__solver':['lbfgs'],\n",
    "        'clf__max_iter':[300, 500, 800],\n",
    "        'clf__random_state':[1]\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86373\n",
      "Grid: {'clf__alpha': 0.1, 'clf__max_iter': 500, 'clf__solver': 'lbfgs', 'clf__activation': 'tanh', 'clf__random_state': 1, 'clf__hidden_layer_sizes': (4,)}\n"
     ]
    }
   ],
   "source": [
    "best_score, best_grid = get_best_score(X_train, y_train, X_val, y_val, pipeline, param_grid)\n",
    "print(\"Accuracy: {:.5f}\".format(best_score))\n",
    "print(\"Grid: {}\".format(best_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score after tuning on 30% validation: 86.1809%\n"
     ]
    }
   ],
   "source": [
    "y_pred = get_accuracy(pipeline, best_grid, X_train, y_train, X_test, y_test, \n",
    "                      'tuning on 30% validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.c**  \n",
    "Finally, what was your best accuracy on the test set using 5-fold cross validation?  \n",
    "\n",
    "**8.c.i** For this question, use 5-fold cross-validation of the training set in order to tune your parameters and find the best model. After finding the tuning parameter values that give you the best cross-validated accuracy, train the model on the entire training set using those parameter values then use this trained model to predict the real test set and report your accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# updating X_train, y_train, X_val, y_val for 5-fold cross-validation\n",
    "X_train = df_train[[\"exercisehours\", \"eyecolor\", \"year\", \"exercise\", \"height\"]].copy().to_dict(orient='records')\n",
    "y_train = df_train['gender']\n",
    "\n",
    "# final parameter grid for 8.c. the initial one is included above for reference\n",
    "param_grid = [{\n",
    "        'clf__hidden_layer_sizes': [(4,),(10,)],\n",
    "        'clf__activation': ['tanh', 'relu'],\n",
    "        'clf__alpha':[0.15, 0.1, 0.2],\n",
    "        'clf__max_iter':[500, 1000],\n",
    "        'clf__random_state':[1]\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.850\n",
      "Best parameters set:\n",
      "MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(4,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   37.7s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid, n_jobs=-1, verbose=1, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "print(best_parameters['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score after 5-fold validation: 86.4322%\n"
     ]
    }
   ],
   "source": [
    "y_pred = get_accuracy(pipeline, best_parameters, X_train, y_train, X_test, y_test, \n",
    "                      '5-fold validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.c.ii** Please submit a file called test_set_prediction.txt that includes the predictions (between 0 and 1) of the test set. The predictions should be in the same order as the original test set file.  \n",
    "\n",
    "Please also submit a file called cv_predictions.txt that includes the predictions (between 0 and 1) of the cross-validated training set. The predictions should be in the same order as the original training set file.These two files will help demonstrate the value of ensemble prediction in the next lab.  \n",
    "\n",
    "NOTE: See documentation for cross-validation strategies in Python scikit-learn. The cross_val_score function is the simplest to use for this assignment- it takes as inputs the model, features, labels, and number of folds and outputs an array of accuracies over each fold. The KFold iterator function produces indices for training and testing sets, and is good to use when you want to examine custom error metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score after 5-fold validation on training: 85.4088%\n"
     ]
    }
   ],
   "source": [
    "y_pred_cvtrain = get_accuracy(pipeline, best_parameters, X_train, y_train, X_train, y_train, \n",
    "                              '5-fold validation on training')\n",
    "pd.DataFrame(y_pred).to_csv(\"test_set_prediction.txt\")\n",
    "pd.DataFrame(y_pred_cvtrain).to_csv(\"cv_predictions.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.d**   \n",
    "Please describe which hold out strategy resulted in highest accuracy on the real test set and the tuning parameter values you used to achieve your high score. Please write up how you went about trying to achieve your accuracy improvement. How many tuning parameter combinations do you use, did you methodologically sweep a range of parameters with some increment? Which changes had the most impact on accuracy improvement? Did you reduce the size of the training set to save computation time? What was the impact of this reduction on accuracy?\n",
    "\n",
    "**Answer**   \n",
    "Training on just the training set as the hold out gave us suspiciously good answers, but on closer inspection it wasn't that suprising given the signifcant overlap between the train and test sets. We would argue that the cross validation results would be more robust to foreign data sets. \n",
    "\n",
    "While tuning hyper-parameters, we followed the following approach. For tuning the MLP Classifier, we tested a myriad combination of hyper-parameters. We started with testing the architecture of the Net. We experimented with multiple as well as single layers, and also tried to vary the width or size of each layer. We found the 4 perceptrons in a single hidden layer was the sweet spot. We also tuned We went through a sweep of all other hyper paramenters, starting with large intervals and subsquently zooming in on the best intervals to find the best values. We tried a combination of values for Alpha, but the majority of tweaking came in terms of the activation functions or the solvers that we used. Interestingly, adam, the default solver never looked like a candidate in any of our solutions.\n",
    "\n",
    "An aspect that affected our training time for these nets (other than the architecture), were the number of iterations. Especially for part 8a, the performance increase greatly with an increased number of iterations with tanh as an activation function. We were sure to always note whether the high scores were at the edge of the value list we had entered, and increased them gradually if that was the case. Though number of iterations was time consuming, thankfully we had access to compute resources that ensured that we did not have to compromise by not increasing a number further during validation. Hopefully, we did not compromise on accuracy for the sake of time saving during training."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
